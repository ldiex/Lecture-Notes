#import "@preview/showybox:2.0.4": showybox

#import "@preview/equate:0.3.2": equate
#import "@preview/ilm:1.4.1": *
#import "@preview/finite:0.5.0": automaton
#import "@preview/finite:0.5.0"

#import "@preview/algorithmic:1.0.7"
#import algorithmic: style-algorithm, algorithm-figure

#show: style-algorithm

#set text(font:("Libertinus Serif", "Source Han Serif SC"))

#show heading.where(level: 1): set text(navy.lighten(0%))
#show heading.where(level: 2): set text(navy.lighten(20%))
#show heading.where(level: 3): set text(navy.lighten(40%))

#show ref: it => {
  text(purple.darken(30%), it)
}

#show: ilm.with(
  title: [复杂系统决策智能],
  date: datetime.today(),
  author: "Tianli Pan",
  table-of-contents: outline(depth: 2),
)

#show: equate.with(breakable: true, sub-numbering: true)
#set math.equation(numbering: "(1.1)")

#set heading(numbering: "1.1.1")
#set page(numbering: "1")
#set text(14pt)
#show raw: set text(font: ("Maple Mono NF"), size: 12pt)

#let frameSettings = (
  border-color: navy,
  title-color: navy.lighten(30%),
  body-color: navy.lighten(95%),
  footer-color: navy.lighten(80%)
)

#let frameSettingsEastern = (
  border-color: eastern,
  title-color: eastern.lighten(30%),
  body-color: eastern.lighten(95%),
  footer-color: eastern.lighten(80%)
)

= 神经网络 (NN)
== 动机和发展历史
神经网络 (Neural Network, NN) 或者 人工神经网络 (Artificial Neural Network, ANN) 是一种模拟生物神经系统结构和功能的计算模型. 它由大量简单的处理单元 (称为神经元或节点) 通过连接 (称为权重) 组成, 这些连接可以传递信号并进行信息处理.

=== 基本构成单元
神经网络的基本构成单元是 *人工神经元* (Artificial Neuron), 也称为 *感知器* (Perceptron). 每个神经元接收多个输入信号, 每个输入信号都有一个对应的权重. 神经元对输入信号进行加权求和, 并通过一个激活函数 (Activation Function) 产生输出信号.

人工神经元模型应具有生物神经元的六个基本特性:
1. 神经元及其联接
2. 神经元之间的联接强度决定信号传递的强弱
3. 神经元之间的联接强度可以随训练改变
4. 信号可以是起刺激作用的，也可以是起抑制作用的
5. 一个神经元接受的信号的累积效果决定该神经元的状态
6. 每个神经元可以有一个 "阈值" (Threshold), 只有当累积信号超过该阈值时, 神经元才会被激活并产生输出信号.

== 典型结构和分类
=== 前向网络 (Feedforward Network)
前向网络 (或称前馈网络) 的特点是信号只被允许从较低层流向较高层, 信号由输入层到输出层进行单向传输.

前向网络包括 *输入层*, *隐藏层* 和 *输出层*. 输入层接收外部输入信号, 隐藏层进行处理, 输出层产生最终输出. 前馈型网络中的每层神经元仅与其前一层的神经元相连, 仅接受前一层传输来的信息.

*单层感知器* 是最早使用且最简单的神经网络结构, 由一个或多个线性阈值单元组成, 但能力非常有限, 一般较少使用.

*典型结构示例*
- BP 神经网络 (BP-NN): 由输入层、隐藏层和输出层组成, 通过反向传播算法进行训练.
- 径向基函数网络 (RBF): 使用径向基函数作为激活函数, 适用于函数逼近和分类任务.
- 卷积神经网络 (CNN): 主要用于图像处理, 通过卷积层提取特征, 具有局部连接和权重共享的特点.

=== 反馈网络 (Feedback Network)
反馈网络的特点是将输出信号反馈到输入端 (类似于自动控制系统中的犯困回路) 从而构成一个多层的循环网络. 网络的输入层不仅接受外界的输入信号, 同时接受网络自身的输出信号.

这里反馈信号可以是原始的输出信号, 经过转化的输出信号, 也可以是本时刻的输出信号或经过一定延迟的输出信号. 

由于反馈信号的存在, 输入的原始信号会被逐步地 "加强" 和 "修复". 这类似于大脑的短期记忆特征 (看到的东西不是一下子就从脑海里消失的).

*稳定性*: 反馈信号会导致网络输出不断变化. 我们期望这种变化逐渐减小并最后消失, 此时网络达到平衡状态. 如果变化不能消失, 则网络不稳定.

*典型结构示例*
- 循环网络 (Hopfield Network): 一种递归神经网络, 主要用于联想记忆和优化问题.
- 全互联网络 (Fully Interconnected Network): 每个神经元与其他所有神经元相连, 适用于复杂的模式识别任务.

== 学习算法
=== 学习的本质、目标与机制
学习的本质是 *对各连接权值的动态调整*. 学习规则是指在学习过程中, 网络中各神经元的连接权变化所依据的一定的调整规则. 

神经网络的学习 (或训练) 过程是: 在外界输入样本的刺激下, 网络不断改变其连接权值, 以使网络的输出不断地接近期望的输出.

从生物学角度来看, 人工神经元模型应具有生物神经元的特性之一, 即神经元之间的联接强度是可以随训练改变的.
=== 按学习方式区分神经网络
- 监督学习 (Supervised Learning): 通过提供输入输出对 (训练样本) 来指导网络学习, 使网络能够正确映射输入到输出. 典型算法包括反向传播算法 (Backpropagation).

- 无监督学习 (Unsupervised Learning): 网络通过输入数据的内在结构进行学习, 不需要预先提供输出标签. 典型算法包括聚类算法 (如自组织映射网络).

- 强化学习 (Reinforcement Learning): 网络通过与环境的交互, 根据奖励信号调整其行为策略. 典型算法包括 Q 学习和策略梯度方法.

=== 主要的学习算法与训练过程
*梯度下降法 (Gradient Descent)*: 梯度下降算法是用来求函数最小值的算法, 每次迭代都沿着梯度的反方向 (即函数值下降最快的方向) 去修改值, 从而走到函数的最小值附近. 在人工神经网络的算法中, 梯度下降法经常被用来求函数的局部最小值, 并且通常人为地设定迭代步长 (学习率)  (常量或者单调减小) .  

梯度下降法算法结构简单，但一般来说只能找到一个局部最小点，且收敛速度较慢.

*反向传播算法 (Backpropagation, BP)*: 反向传播算法是一种用于训练多层前馈神经网络的监督学习算法. 它通过计算输出误差相对于各层权重的梯度, 并将误差信号从输出层反向传播到输入层, 以调整权重. 

*RBF 网络训练算法*: RBF 网络的训练通常分为两个阶段: 第一阶段是确定径向基函数的中心和宽度, 第二阶段是通过线性回归方法计算输出层的权重.

RBF 网络已被证明具有惟一最佳逼近的特性, 并且无局部极小问题.

== BP 神经网络 (BP-NN)
略
== 其他常见神经网络
=== RBF 神经网络
RBF神经网络, 全称径向基函数神经网络 (Radial Basis Function Neural Network), 是一种以径向基函数作为激活函数的前馈神经网络. 它的结构通常分为三层: 输入层, 隐藏层和输出层. 隐藏层的每个神经元对应一个径向基函数, 一般采用高斯函数, 其输出取决于输入向量与某个中心点之间的距离. 

与传统的多层感知机 (MLP) 不同, RBF网络的隐藏层不进行线性加权求和, 而是衡量输入与中心的 "相似性" 或 "接近程度". 这种机制让RBF网络特别擅长对局部模式进行建模, 在函数逼近, 时间序列预测, 模式分类等任务中表现出色. 也就是说, 每个RBF隐藏神经元的输出不是像普通神经网络那样计算 $w^T x + b$, 而是计算输入向量和某个预设中心点 $c$ 之间的距离 $||x - c||$ , 然后通过径向基函数 (如高斯函数) 转换为输出值:
$
  phi (x) = exp(-(||x - c||^2) / (2 sigma^2))
$

RBF网络的核心思想是: 用一组局部响应的基函数去线性组合逼近目标函数. 训练过程通常分两步:
1. 确定隐藏层的中心 $c$ (可通过对训练样本做聚类如K-means, 或直接取训练样本) 
2. 用线性方法 (如最小二乘) 求解输出层权重. 

这种分阶段训练方式使得 RBF 网络收敛速度快, 且不易陷入局部极小. 

不过, RBF网络也有局限. 它的表达能力受限于基函数的数量和位置, 对高维数据容易遭遇 "维度灾难" , 且缺乏像深度网络那样的层次化特征提取能力. 因此, 在现代深度学习兴起后, RBF网络在主流视觉或自然语言任务中已较少使用.
=== CNN 神经网络
略

= 模糊逻辑和模糊计算
== 模糊逻辑
模糊逻辑是用来解决在试图用精确的数学语言处理现实生活中的问题时, 精确数学语言与模糊思维习惯之间产生的矛盾的工具之一. 

在经典二值逻辑中, 一个命题非真即假, 通常用 0 表示 "假" , 用 1 表示 "真" . 在模糊逻辑中, 一个命题不再非真即假, 它可以被认为是*"部分的真"*. 模糊逻辑取消了二值之间非此即彼的对立, 用隶属度表示二值间的过渡状态.

和概率论不同的是, 概率论处理的是事件发生的不确定性, 而模糊逻辑处理的是概念本身的模糊性.

== 模糊集合 (Fuzzy Set)
=== 古典集合
在古典集合论中, 一个集合是由一些确定的元素组成的整体. 对于一个集合 $A$ , 如果一个元素 $x$ 属于集合 $A$ , 则记作 $x in A$ ; 否则记作 $x in.not A$ . 这种关系是非此即彼的.

对于论域 $U$ 上的任意一个集合 $A$, 它都可以用它的 *特征函数* (Characteristic Function) $C_A (x)$ 来表示:
$
  C_A: U -> {0, 1} \
  C_A (x) = cases(
    1\, "if" x in A,
    0\, "if" x in.not A
  )
$

=== 模糊集合
模糊集合是对古典集合的推广. 在模糊集合中, 元素与集合之间的关系不再是非此即彼的, 而是通过一个取值在 [0, 1] 之间的隶属度 (Membership Degree) 来表示元素属于集合的程度.

对于论域 $U$ 上的一个模糊集合 $A$, 它可以用它的 *隶属函数* (Membership Function) $f_A (x)$ 来表示:
$
  f_A: U -> [0, 1] \
  f_A (x) = "degree of membership of" x "in" A
$

古典集合可以看作一种退化的模糊集合, 其中不属于该集合的元素隶属度为 0, 其余元素隶属度为 1.

=== 隶属度函数的确定
隶属度函数的选择通常依赖于相关领域的专家知识. 常用的选择方法包括: 模糊统计法, 例证法, 专家经验法和二元对比排序法. 常见的函数有: 三角形函数, 梯形函数, Sigmoid 函数和高斯函数.

但是, 隶属度函数的选择应该满足以下原则:
1. 表示隶属度函数的模糊集合必须是 *凸模糊集合* (呈单峰馒头形), 即隶属度函数在其最大值处达到峰值, 并且在峰值两侧单调递减. 这是因为, 在实际问题中, 通常假设某个元素的隶属度越高, 它与该集合的 "接近程度" 越高.
2. 模糊变量的标称值选择一般取 3—9 个为宜, 通常取奇数. 这是因为, 过少的标称值会导致信息损失, 而过多的标称值会增加计算复杂度和难以解释. 取奇数可以确保存在一个中间值, 便于表示 "中等" 或 "适中" 的概念.
3. 隶属度函数要符合人们的语义顺序, 避免不恰当的重叠

=== 模糊集合的基本运算
模糊集合的基本运算包括: 子集, 并集, 交集和补集. 

- *子集* (Subset): 对于论域 $U$ 上的两个模糊集合 $A$ 和 $B$, 如果对于所有 $x in U$ , 都有 $f_A (x) <= f_B (x)$ , 则称 $A$ 是 $B$ 的子集, 记作 $A subset.eq B$ .

- *并集* (Union): 对于论域 $U$ 上的两个模糊集合 $A$ 和 $B$, 它们的并集 $C = A union B$ 的隶属函数定义为:
$
  f_C (x) = max(f_A (x), f_B (x))
$

- *交集* (Intersection): 对于论域 $U$ 上的两个模糊集合 $A$ 和 $B$, 它们的交集 $C = A inter B$ 的隶属函数定义为:
$
  f_C (x) = min(f_A (x), f_B (x))
$

- *补集* (Complement): 对于论域 $U$ 上的一个模糊集合 $A$, 它的补集 $A^c$ 的隶属函数定义为:
$
  f_(A^c) (x) = 1 - f_A (x)
$

这些运算也满足一些基本定律, 如
- 交换律: $A union B = B union A$, $A inter B = B inter A$
- 结合律: $(A union B) union C = A union (B union C)$, $(A inter B) inter C = A inter (B inter C)$
- 分配律: $A inter (B union C) = (A inter B) union (A inter C)$, $A union (B inter C) = (A union B) inter (A union C)$

== 模糊推理和计算
模糊推理是从模糊规则 (if-then 规则) 已知事实中得出结论的推理过程. 它是一种不精确的推理, 是通过模糊规则将给定输入转化为输出的过程.

=== 模糊规则
模糊规则是进行模糊推理时所依赖的规则, 通常可以用自然语言表述. 模糊规则的一般形式是 "If x is A then y is B", 其中 A 和 B 是模糊集合. 

在模糊推理中, 小前提 (输入) 没有必要与大前提 (规则) 的前件一致. 比如说, 规则是 "If temperature is high then fan speed is fast", 如果输入是 "temperature is very high", 那么小前提和大前提并不一致, 但是在模糊推理中仍然可以进行推理.

=== 语言变量与语言算子
模糊推理中依赖于语言变量来表达模糊概念:

- *语言变量* (Linguistic Variable): 语言变量是指取值为词语或句子的变量. 例如, "temperature" 可以是一个语言变量, 它的取值可以是 "low", "medium", "high" 等等. 我们表示为 $T("temperature") = {"low", "medium", "high"}$ .

- *语言算子* (Linguistic Operator): 语言算子是用来操作语言变量的词语或短语. 常见的语言算子包括 "very", "more or less", "not" 等等. 例如, "very high" 可以表示为 $f_("very high") (x) = (f_("high") (x))^2$, 而 "probably high" 可以表示为 $f_("probably high") (x) = sqrt(f_("high") (x))$ .

=== 模糊计算的基本流程
1. *模糊化接口* (Fuzzification Interface): 将精确输入转化为模糊集合. 例如, 将温度值 30°C 转化为 "high" 的隶属度.
2. *模糊规则库* (Fuzzy Rule Base): 包含用模糊语言变量表示的一系列控制规则, 反映了控制专家的经验和知识. 规则库还包括数据库, 如语言变量的隶属度函数和尺度变换因子等.
3. *推理方法* (Inference Method): 是模糊控制器的核心. 它根据模糊规则和输入对模糊集的隶属度, 得到模糊结论的方法.
4. *去模糊化接口* (Defuzzification Interface): 将模糊结论转化为精确输出. 包含将模糊控制量转化为论域范围的清晰量, 并进行尺度变换以获得实际控制量.

= 遗传算法 (GA)
== 动机
遗传算法 (GA) 是进化计算的一个分支. 它是一种模拟自然界生物进化过程的迭代式自适应概率性全局优化搜索算法. 它通过模拟生物进化中的自然选择和交配变异来寻找问题的全局最优解, 在人工系统中实现待定目标的优化. 

遗传算法借鉴了生物进化的两个核心理论: 达尔文的进化论和孟德尔的遗传学

*达尔文的进化论 (自然选择原理)*:
生物个体在其生存环境中存在差异, 这些差异会影响个体的生存和繁殖能力. 适应环境的个体更有可能生存下来并将其基因传递给下一代, 而不适应环境的个体则更可能被淘汰. 在遗传算法中, *适应度函数* 用来衡量个体的优劣, 适应度高的个体有更大的概率被选中进行繁殖.

*孟德尔的遗传学 (基因重组和变异)*:
生物个体通过基因重组和变异产生后代, 这些遗传操作引入了新的基因组合和变异, 增加了种群的多样性. 在遗传算法中, *交叉操作* 模拟基因重组, *变异操作* 模拟基因突变, 以探索解空间.

== 标准遗传算法 (SGA)
SGA 是一种统一的最基本的遗传算法, 它只使用选择, 交叉, 变异这三种基本遗传算子.  SGA 的遗传进化操作过程简单, 易于理解. 它不仅给各种遗传算法提供了一个基本框架, 同时也具有一定的应用价值.

我们下面使用 OneMax 问题来说明 SGA 的基本流程. OneMax 问题是一个简单的优化问题, 其目标是最大化一个二进制字符串中 1 的数量. 例如, 对于一个长度为 5 的二进制字符串 "11010", 其 OneMax 值为 3 (因为有三个 1). 我们下面设定字符串长度为 8.

1. *染色体编码*: SGA 使用固定长度的二进制符号串来表示群体中的个体, 其等位基因由 0 和 1 两种符号组成. 每个染色体表示问题的一个可行解. 所以我们需要根据解的取值范围和规定精度来确定染色体的长度 $L$. 在 OneMax 问题中, 我们设定染色体长度为 8, 因此每个个体可以表示为一个 8 位的二进制字符串.

2. *群体初始化*: 随机生成初始群体, 每个个体的染色体由随机的 0 和 1 组成. 假设我们设定群体大小为 4, 则初始群体可能如下:
#align(center)[
个体 1: 11010010 \
个体 2: 00101101 \
个体 3: 11100011 \
个体 4: 00011100
]

3. *适应度评估*: 计算每个个体的适应度值, 适应度函数为染色体中 1 的数量. 对于上述初始群体, 适应度值如下:
#align(center)[
个体 1: 4 \
个体 2: 4 \
个体 3: 5 \
个体 4: 3
]

4. *选择算子 (Selection)*: 根据适应度值选择个体进行繁殖. 常用的方法有轮盘赌选择, 锦标赛选择等. 这里我们使用轮盘赌选择, 适应度值越高的个体被选中的概率越大 ($P_i prop f_i$ ). 假设选择结果如下:
#align(center)[
  *选择1*: 个体 3 (11100011) \
  *选择2*: 个体 1 (11010010) \
  *选择3*: 个体 2 (00101101) \
  *选择4*: 个体 3 (11100011)
]

5. *交叉算子 (Crossover)*: 以一定的交叉概率 $P_c$ 对选择出来的个体进行交叉操作, 生成新的个体. 这里我们设定 $P_c = 0.7$. 假设我们对选择的个体进行单点交叉, 交叉点随机选择在第 4 位, 则交叉结果如下:
#align(center)[
  *交叉1*: 个体 3 (1110|0011) 和 个体 1 (1101|0010) 交叉后生成 \
            新个体 A: 11100010 \
            新个体 B: 11010011 \
  *交叉2*: 个体 2 (0010|1101) 和 个体 3 (1110|0011) 交叉后生成 \
            新个体 C: 00100011 \
            新个体 D: 11011110
]

6. *变异算子 (Mutation)*: 以一定的变异概率 $P_m$ 对新个体进行变异操作, 这里我们设定 $P_m = 0.01$. 假设在本次迭代中没有发生变异, 则变异结果如下:
#align(center)[
  新个体 A: 11100010 \
  新个体 B: 11010011 \
  新个体 C: 00100011 \
  新个体 D: 11011110
]

7. *新群体形成*: 将变异后的个体组成新的群体, 替代旧群体. 

8. *终止条件检查*: 检查是否满足终止条件, 如达到最大迭代次数或找到满意解. 如果不满足, 则返回步骤 3 继续迭代. 


== 遗传算法的改进
=== 遗传算子多样性的改进
*交配算子改进*: 除了 SGA 的单点交叉, 还包括多点交叉 (破坏性更强, 有助于促进搜索), 均匀交叉 (父本基因以相同概率交换).

*变异算子改进*: 除了 SGA 的简单位翻转, 还包括非均匀变异 (变异幅度随代数变化), 高斯变异 (适用于实数编码).

*选择机制改进*: 除了轮盘赌选择, 还包括锦标赛选择 (更稳定), 排序选择 (避免适应度过大个体垄断).

=== 运行参数的自适应调整
可以采用自适应方法在算法运行过程中动态调整交叉概率 $P_c$ 和变异概率 $P_m$ , 以平衡探索 (exploration) 和利用 (exploitation) 之间的关系. 例如, 当群体多样性较低时, 增加变异概率以促进探索; 当群体多样性较高时, 减少变异概率以加强利用.

== 混合遗传算法 (HGA)
将遗传算法作为 "全局搜索" 框架, 与其他具有 "局部搜索" 能力的算法融合.

通过引入爬山法, 模拟退火等局部搜索策略, 在遗传算法的每一代或若干代后对当前最优个体进行局部优化, 以加快收敛速度并提高解的质量.

= 粒子群优化 (PSO)
== 动机
PSO 最初的灵感直接源自对鸟群觅食行为的仿真研究. 在广阔的区域内, 如果只有一块食物, 成群的鸟儿在随机搜索时, 单只鸟并不知道食物的确切位置, 但它们能感知距离食物的远近.

PSO 的核心思想在于通过记忆与社会协作来驱动搜索. 每一个被视为 "粒子" 的解, 都拥有两个关键的引导力量: 
1. *个体认知*: 粒子记忆中自身的最佳位置 (pBest), 代表了个体过去的成功经验.
2. *社会认知*: 粒子能够感知到整个群体目前发现的全局最优位置 (gBest), 代表了群体的集体智慧.

在这种思想下, 粒子的下一次飞行方向是由当前速度, 向自身最优靠拢的冲动以及向群体最优靠拢的意愿共同决定的. 这种分散式搜寻与集中式反馈的平衡, 使得 PSO 既能保留个体探索的多样性, 又能通过群体智慧迅速向高价值区域汇聚.
== 核心概念
在粒子群优化算法 (PSO) 中, 问题的每一个潜在解都被抽象为在 $D$ 维搜索空间中飞行的粒子. 算法通过模拟这些粒子在空间中的运动来实现寻优.

=== 核心概念
- *粒子群规模* $N$: 粒子群中粒子的数量. 较大的群体规模有助于增加搜索的多样性, 但也会增加计算开销.
- *位置向量* $x_i = (x_(i 1), x_(i 2), ..., x_(i D))$: 粒子 $i$ 在 $D$ 维搜索空间中的当前位置, 代表一个潜在解.
- *速度向量* $v_i = (v_(i 1), v_(i 2), ..., v_(i D))$: 粒子 $i$ 在 $D$ 维搜索空间中的当前速度, 决定了粒子在下一次迭代中的位置变化.
- *个体最优位置* $"pBest"_i$: 粒子 $i$ 迄今为止所经历的最佳位置, 即该粒子在历史上找到的最优解.
- *全局最优位置* $"gBest"$: 群体中所有粒子迄今为止找到的最佳位置, 代表了整个群体的最优

=== 核心公式
*速度更新公式*:
$
  v_i^(t + 1) = omega dot.c v_i^t + c_1 dot.c r_1 dot.c ("pBest"_i - x_i^t) + c_2 dot.c r_2 dot.c ("gBest" - x_i^t)
$
这里 $omega$ 是惯性权重, 控制粒子当前速度对下一速度的影响; $c_1$ 和 $c_2$ 是学习因子, 分别控制粒子向个体最优和全局最优位置靠拢的程度; $r_1$ 和 $r_2$ 是在 [0, 1] 之间均匀分布的随机数, 引入随机性以增强搜索能力.

*位置更新公式*:
$
  x_i^(t + 1) = x_i^t + v_i^(t + 1)
$
== 算法流程

#algorithm-figure(
  "Particle Swarm Optimization (PSO)",
  vstroke: .5pt + luma(200),
  {
    import algorithmic: *
    Procedure(
      "PSO-Search",
      ($N$, $D$, $T_("max")$),
      {
        Comment[阶段 1: 初始化粒子群]
        For(
          $i = 1, ..., N$,
          {
            LineComment(Assign[$x_i$][RandomPosition($D$)], [随机初始化 $D$ 维位置])
            LineComment(Assign[$v_i$][RandomVelocity($D$)], [随机初始化 $D$ 维速度])
            Assign[$"pBest"_i$][$x_i$]
            Comment[计算初始适应度并确定全局最优]
            If(
              $f("pBest"_i) < f("gBest")$,
              {
                Assign[$"gBest"$][$"pBest_i"$]
              }
            )
          }
        )
        
        LineBreak
        Comment[阶段 2: 演化迭代]
        Assign[$t$][$0$]
        While(
          $t < T_("max") "and not Terminated"$,
          {
            For(
              $i = 1, ..., N$,
              {
                Comment[依据核心公式更新速度与位置]
                Assign[$v_i$][$omega v_i + c_1 r_1 ("pBest"_i - x_i) + c_2 r_2 ("gBest" - x_i)$]
                Assign[$x_i$][$x_i + v_i$]
                
                LineBreak
                Comment[评估新位置的适应度]
                If(
                  $f(x_i) < f("pBest"_i)$,
                  {
                    Assign[$"pBest"_i$][$x_i$]
                    If(
                      $f("pBest"_i) < f("gBest")$,
                      {
                        Assign[$"gBest"$][$"pBest"_i$]
                      }
                    )
                  }
                )
              }
            )
            Assign[$t$][$t + 1$]
          }
        )
        Return[$"gBest"$]
      },
    )
  }
)

= 贝叶斯网络
贝叶斯网络 (Bayesian Network) 通过有向无环图 (Directed Acyclic Graph, DAG) 来刻画变量之间的因果结构与条件独立性. 

DAG 的有向性表示变量之间的因果关系, 无环性确保不存在自我循环的依赖. 每个节点代表一个随机变量, 边表示变量之间的直接影响.

一个贝叶斯网络由两个核心组件定义:
- *结构* $G$: 一个由节点和有向边组成的图。每个节点代表一个随机变量 $X_i$, 而有向边 $X_j -> X_i$ 则表示变量之间的直接依赖关系. 在这个结构中, $X_j$ 被称为 $X_i$ 的父节点 (Parent), 记作 $"Pa"(X_i)$.

- *参数* $theta$: 对于每个节点 $X_i$, 给定其父节点的取值, 定义条件概率分布 $P(X_i | "Pa"(X_i))$. 这些条件概率分布量化了变量之间的依赖关系.

根据概率的链式法则, 任何联合分布都可以展开, 但贝叶斯网络利用图结构引入了局部马尔可夫性质: *每个随机变量在给定其父母节点的情况下, 与其所有非后代节点独立*. 基于这一性质, 全变量的联合概率分布可以被形式化地分解为所有节点局部条件概率的乘积: 
$
  P(X_1, X_2, ..., X_n) = product_(i=1)^n P(X_i | "Pa"(X_i))
$
= 静态规划
= 动态规划
== 最优控制问题
寻找一个控制策略 $u(t)$, 使得性能指标 $J(u)$ 最小化.

对于连续时间系统
$
  dot(x) = f(x, u, t)
$
其性能指标为
$
  J(u) = h(x(t_f), t_f) + integral_(t_0)^(t_f) g(x(t), u(t), t) dif t
$
这里的两项分别表示终端成本和运行成本.

对于离散时间系统, 也可以类似地定义
$
  x(k + 1) = f_D (x, u, k); \ J(u) = h_D (x(N), N) + sum_(k=0)^(N-1) g_D (x(k), u(k), k)
$

== Bellman 最优性原理
Bellman 最优性原理指出, 一个最优策略的子策略也是最优. 也就是说, 如果从时间 $t_0$ 到 $t_f$ 的最优控制策略是 $u^*(t)$, 那么对于任意时间点 $t_1$ 满足 $t_0 < t_1 < t_f$, 从 $t_1$ 到 $t_f$ 的子策略 $u^*(t)$ 仍然是所有可能策略中最优的.

== Bellman 方程 (离散时间)
基于最优性原理, 我们可以推导出离散时间系统的动态规划方程, 即 Bellman 方程.

定义 *最优价值函数* (Optimal Value Function) $V^*(x(k), k)$ 为从时刻 $k$ 状态 $x(k)$ 出发, 采取最优策略直到终端时刻 $N$ 所能获得的最小代价:
$
  V^*(x(k), k) = min_(u(k), ..., u(N-1)) { h_D (x(N), N) + sum_(j=k)^(N-1) g_D (x(j), u(j), j) }
$

根据最优性原理, 我们可以将上述优化问题分解为两步: 当前时刻的优化和剩余时刻的优化. 这就得到了递归形式的 Bellman 方程:
$
  V^*(x(k), k) = min_(u(k)) { g_D (x(k), u(k), k) + V^*(f_D (x(k), u(k), k), k+1) }
$
边界条件为终端时刻的代价:
$
  V^*(x(N), N) = h_D (x(N), N)
$
这个方程说明, 当前状态的最优价值等于 "当前一步的运行代价" 加上 "下一时刻状态的最优价值" 的最小值. 我们可以通过从 $N$ 时刻逆向递推到 $0$ 时刻来求解最优控制序列.

== HJB 方程 (连续时间)
对于连续时间系统, 动态规划的对应形式被称为 Hamilton-Jacobi-Bellman (HJB) 方程. 它是 Bellman 方程在时间间隔趋于零时的极限形式.

类似于离散情况, 定义最优价值函数 $V^*(x(t), t)$ 为:
$
  V^*(x(t), t) = min_(u(tau), t <= tau <= t_f) { h(x(t_f), t_f) + integral_(t)^(t_f) g(x(tau), u(tau), tau) dif tau }
$

对 $V^*(x(t), t)$ 进行泰勒展开并取极限, 可以推导出 HJB 偏微分方程:
$
  - (partial V^*) / (partial t) = min_(u(t)) { g(x(t), u(t), t) + ((partial V^*) / (partial x))^T f(x(t), u(t), t) }
$
边界条件为:
$
  V^*(x(t_f), t_f) = h(x(t_f), t_f)
$

HJB 方程是一个非线性偏微分方程, 通常很难求得解析解, 往往需要借助数值方法求解. 它是现代控制理论和强化学习 (尤其是基于模型的强化学习) 的理论基石.